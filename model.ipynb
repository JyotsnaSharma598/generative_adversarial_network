{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"authorship_tag":"ABX9TyOhJvtnJsSvRTcYTc3zyh47"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FhdosoBR0BLY","colab_type":"code","colab":{}},"source":["\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","from miscc.config import cfg\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","\n","\n","# ############################## For Compute inception score ##############################\n","# Besides the inception score computed by pretrained model, especially for fine-grained datasets (such as birds, bedroom),\n","#  it is also good to compute inception score using fine-tuned model and manually examine the image quality.\n","class INCEPTION_V3(nn.Module):\n","    def __init__(self):\n","        super(INCEPTION_V3, self).__init__()\n","        self.model = models.inception_v3()\n","        url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n","        # print(next(model.parameters()).data)\n","        state_dict = \\\n","            model_zoo.load_url(url, map_location=lambda storage, loc: storage)\n","        self.model.load_state_dict(state_dict)\n","        for param in self.model.parameters():\n","            param.requires_grad = False\n","        print('Load pretrained model from ', url)\n","        # print(next(self.model.parameters()).data)\n","        # print(self.model)\n","\n","    def forward(self, input):\n","        # [-1.0, 1.0] --> [0, 1.0]\n","        x = input * 0.5 + 0.5\n","        # mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]\n","        # --> mean = 0, std = 1\n","        x[:, 0] = (x[:, 0] - 0.485) / 0.229\n","        x[:, 1] = (x[:, 1] - 0.456) / 0.224\n","        x[:, 2] = (x[:, 2] - 0.406) / 0.225\n","        #\n","        # --> fixed-size input: batch x 3 x 299 x 299\n","        x = nn.Upsample(size=(299, 299), mode='bilinear')(x)\n","        # 299 x 299 x 3\n","        x = self.model(x)\n","        x = nn.Softmax()(x)\n","        return x\n","\n","\n","class GLU(nn.Module):\n","    def __init__(self):\n","        super(GLU, self).__init__()\n","\n","    def forward(self, x):\n","        nc = x.size(1)\n","        assert nc % 2 == 0, 'channels dont divide 2!'\n","        nc = int(nc/2)\n","        return x[:, :nc] * F.sigmoid(x[:, nc:])\n","\n","\n","def conv3x3(in_planes, out_planes):\n","    \"3x3 convolution with padding\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n","                     padding=1, bias=False)\n","\n","\n","# ############## G networks ################################################\n","# Upsale the spatial size by a factor of 2\n","def upBlock(in_planes, out_planes):\n","    block = nn.Sequential(\n","        nn.Upsample(scale_factor=2, mode='nearest'),\n","        conv3x3(in_planes, out_planes * 2),\n","        nn.BatchNorm2d(out_planes * 2),\n","        GLU()\n","    )\n","    return block\n","\n","\n","# Keep the spatial size\n","def Block3x3_relu(in_planes, out_planes):\n","    block = nn.Sequential(\n","        conv3x3(in_planes, out_planes * 2),\n","        nn.BatchNorm2d(out_planes * 2),\n","        GLU()\n","    )\n","    return block\n","\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, channel_num):\n","        super(ResBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            conv3x3(channel_num, channel_num * 2),\n","            nn.BatchNorm2d(channel_num * 2),\n","            GLU(),\n","            conv3x3(channel_num, channel_num),\n","            nn.BatchNorm2d(channel_num)\n","        )\n","\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.block(x)\n","        out += residual\n","        return out\n","\n","\n","class CA_NET(nn.Module):\n","    # some code is modified from vae examples\n","    # (https://github.com/pytorch/examples/blob/master/vae/main.py)\n","    def __init__(self):\n","        super(CA_NET, self).__init__()\n","        self.t_dim = cfg.TEXT.DIMENSION\n","        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        self.fc = nn.Linear(self.t_dim, self.ef_dim * 4, bias=True)\n","        self.relu = GLU()\n","\n","    def encode(self, text_embedding):\n","        x = self.relu(self.fc(text_embedding))\n","        mu = x[:, :self.ef_dim]\n","        logvar = x[:, self.ef_dim:]\n","        return mu, logvar\n","\n","    def reparametrize(self, mu, logvar):\n","        std = logvar.mul(0.5).exp_()\n","        if cfg.CUDA:\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)\n","\n","    def forward(self, text_embedding):\n","        mu, logvar = self.encode(text_embedding)\n","        c_code = self.reparametrize(mu, logvar)\n","        return c_code, mu, logvar\n","\n","\n","class INIT_STAGE_G(nn.Module):\n","    def __init__(self, ngf):\n","        super(INIT_STAGE_G, self).__init__()\n","        self.gf_dim = ngf\n","        if cfg.GAN.B_CONDITION:\n","            self.in_dim = cfg.GAN.Z_DIM + cfg.GAN.EMBEDDING_DIM\n","        else:\n","            self.in_dim = cfg.GAN.Z_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        in_dim = self.in_dim\n","        ngf = self.gf_dim\n","        self.fc = nn.Sequential(\n","            nn.Linear(in_dim, ngf * 4 * 4 * 2, bias=False),\n","            nn.BatchNorm1d(ngf * 4 * 4 * 2),\n","            GLU())\n","\n","\n","        self.upsample1 = upBlock(ngf, ngf // 2)\n","        self.upsample2 = upBlock(ngf // 2, ngf // 4)\n","        self.upsample3 = upBlock(ngf // 4, ngf // 8)\n","        self.upsample4 = upBlock(ngf // 8, ngf // 16)\n","\n","    def forward(self, z_code, c_code=None):\n","        if cfg.GAN.B_CONDITION and c_code is not None:\n","            in_code = torch.cat((c_code, z_code), 1)\n","        else:\n","            in_code = z_code\n","        # state size 16ngf x 4 x 4\n","        out_code = self.fc(in_code)\n","        out_code = out_code.view(-1, self.gf_dim, 4, 4)\n","        # state size 8ngf x 8 x 8\n","        out_code = self.upsample1(out_code)\n","        # state size 4ngf x 16 x 16\n","        out_code = self.upsample2(out_code)\n","        # state size 2ngf x 32 x 32\n","        out_code = self.upsample3(out_code)\n","        # state size ngf x 64 x 64\n","        out_code = self.upsample4(out_code)\n","\n","        return out_code\n","\n","\n","class NEXT_STAGE_G(nn.Module):\n","    def __init__(self, ngf, num_residual=cfg.GAN.R_NUM):\n","        super(NEXT_STAGE_G, self).__init__()\n","        self.gf_dim = ngf\n","        if cfg.GAN.B_CONDITION:\n","            self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        else:\n","            self.ef_dim = cfg.GAN.Z_DIM\n","        self.num_residual = num_residual\n","        self.define_module()\n","\n","    def _make_layer(self, block, channel_num):\n","        layers = []\n","        for i in range(self.num_residual):\n","            layers.append(block(channel_num))\n","        return nn.Sequential(*layers)\n","\n","    def define_module(self):\n","        ngf = self.gf_dim\n","        efg = self.ef_dim\n","\n","        self.jointConv = Block3x3_relu(ngf + efg, ngf)\n","        self.residual = self._make_layer(ResBlock, ngf)\n","        self.upsample = upBlock(ngf, ngf // 2)\n","\n","    def forward(self, h_code, c_code):\n","        s_size = h_code.size(2)\n","        c_code = c_code.view(-1, self.ef_dim, 1, 1)\n","        c_code = c_code.repeat(1, 1, s_size, s_size)\n","        # state size (ngf+egf) x in_size x in_size\n","        h_c_code = torch.cat((c_code, h_code), 1)\n","        # state size ngf x in_size x in_size\n","        out_code = self.jointConv(h_c_code)\n","        out_code = self.residual(out_code)\n","        # state size ngf/2 x 2in_size x 2in_size\n","        out_code = self.upsample(out_code)\n","\n","        return out_code\n","\n","\n","class GET_IMAGE_G(nn.Module):\n","    def __init__(self, ngf):\n","        super(GET_IMAGE_G, self).__init__()\n","        self.gf_dim = ngf\n","        self.img = nn.Sequential(\n","            conv3x3(ngf, 3),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, h_code):\n","        out_img = self.img(h_code)\n","        return out_img\n","\n","\n","class G_NET(nn.Module):\n","    def __init__(self):\n","        super(G_NET, self).__init__()\n","        self.gf_dim = cfg.GAN.GF_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        if cfg.GAN.B_CONDITION:\n","            self.ca_net = CA_NET()\n","\n","        if cfg.TREE.BRANCH_NUM > 0:\n","            self.h_net1 = INIT_STAGE_G(self.gf_dim * 16)\n","            self.img_net1 = GET_IMAGE_G(self.gf_dim)\n","        if cfg.TREE.BRANCH_NUM > 1:\n","            self.h_net2 = NEXT_STAGE_G(self.gf_dim)\n","            self.img_net2 = GET_IMAGE_G(self.gf_dim // 2)\n","        if cfg.TREE.BRANCH_NUM > 2:\n","            self.h_net3 = NEXT_STAGE_G(self.gf_dim // 2)\n","            self.img_net3 = GET_IMAGE_G(self.gf_dim // 4)\n","        if cfg.TREE.BRANCH_NUM > 3: # Recommended structure (mainly limited by GPU memory), and not test yet\n","            self.h_net4 = NEXT_STAGE_G(self.gf_dim // 4, num_residual=1)\n","            self.img_net4 = GET_IMAGE_G(self.gf_dim // 8)\n","        if cfg.TREE.BRANCH_NUM > 4:\n","            self.h_net4 = NEXT_STAGE_G(self.gf_dim // 8, num_residual=1)\n","            self.img_net4 = GET_IMAGE_G(self.gf_dim // 16)\n","\n","    def forward(self, z_code, text_embedding=None):\n","        if cfg.GAN.B_CONDITION and text_embedding is not None:\n","            c_code, mu, logvar = self.ca_net(text_embedding)\n","        else:\n","            c_code, mu, logvar = z_code, None, None\n","        fake_imgs = []\n","        if cfg.TREE.BRANCH_NUM > 0:\n","            h_code1 = self.h_net1(z_code, c_code)\n","            fake_img1 = self.img_net1(h_code1)\n","            fake_imgs.append(fake_img1)\n","        if cfg.TREE.BRANCH_NUM > 1:\n","            h_code2 = self.h_net2(h_code1, c_code)\n","            fake_img2 = self.img_net2(h_code2)\n","            fake_imgs.append(fake_img2)\n","        if cfg.TREE.BRANCH_NUM > 2:\n","            h_code3 = self.h_net3(h_code2, c_code)\n","            fake_img3 = self.img_net3(h_code3)\n","            fake_imgs.append(fake_img3)\n","        if cfg.TREE.BRANCH_NUM > 3:\n","            h_code4 = self.h_net4(h_code3, c_code)\n","            fake_img4 = self.img_net4(h_code4)\n","            fake_imgs.append(fake_img4)\n","\n","        return fake_imgs, mu, logvar\n","\n","\n","# ############## D networks ################################################\n","def Block3x3_leakRelu(in_planes, out_planes):\n","    block = nn.Sequential(\n","        conv3x3(in_planes, out_planes),\n","        nn.BatchNorm2d(out_planes),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    return block\n","\n","\n","# Downsale the spatial size by a factor of 2\n","def downBlock(in_planes, out_planes):\n","    block = nn.Sequential(\n","        nn.Conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(out_planes),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    return block\n","\n","\n","# Downsale the spatial size by a factor of 16\n","def encode_image_by_16times(ndf):\n","    encode_img = nn.Sequential(\n","        # --> state size. ndf x in_size/2 x in_size/2\n","        nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        # --> state size 2ndf x x in_size/4 x in_size/4\n","        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(ndf * 2),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        # --> state size 4ndf x in_size/8 x in_size/8\n","        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(ndf * 4),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        # --> state size 8ndf x in_size/16 x in_size/16\n","        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(ndf * 8),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    return encode_img\n","\n","\n","# For 64 x 64 images\n","class D_NET64(nn.Module):\n","    def __init__(self):\n","        super(D_NET64, self).__init__()\n","        self.df_dim = cfg.GAN.DF_DIM\n","        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        ndf = self.df_dim\n","        efg = self.ef_dim\n","        self.img_code_s16 = encode_image_by_16times(ndf)\n","\n","        self.logits = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","            nn.Sigmoid())\n","\n","        if cfg.GAN.B_CONDITION:\n","            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n","            self.uncond_logits = nn.Sequential(\n","                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","                nn.Sigmoid())\n","\n","    def forward(self, x_var, c_code=None):\n","        x_code = self.img_code_s16(x_var)\n","\n","        if cfg.GAN.B_CONDITION and c_code is not None:\n","            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n","            c_code = c_code.repeat(1, 1, 4, 4)\n","            # state size (ngf+egf) x 4 x 4\n","            h_c_code = torch.cat((c_code, x_code), 1)\n","            # state size ngf x in_size x in_size\n","            h_c_code = self.jointConv(h_c_code)\n","        else:\n","            h_c_code = x_code\n","\n","        output = self.logits(h_c_code)\n","        if cfg.GAN.B_CONDITION:\n","            out_uncond = self.uncond_logits(x_code)\n","            return [output.view(-1), out_uncond.view(-1)]\n","        else:\n","            return [output.view(-1)]\n","\n","\n","# For 128 x 128 images\n","class D_NET128(nn.Module):\n","    def __init__(self):\n","        super(D_NET128, self).__init__()\n","        self.df_dim = cfg.GAN.DF_DIM\n","        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        ndf = self.df_dim\n","        efg = self.ef_dim\n","        self.img_code_s16 = encode_image_by_16times(ndf)\n","        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n","        self.img_code_s32_1 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n","\n","        self.logits = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","            nn.Sigmoid())\n","\n","        if cfg.GAN.B_CONDITION:\n","            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n","            self.uncond_logits = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","            nn.Sigmoid())\n","\n","    def forward(self, x_var, c_code=None):\n","        x_code = self.img_code_s16(x_var)\n","        x_code = self.img_code_s32(x_code)\n","        x_code = self.img_code_s32_1(x_code)\n","\n","        if cfg.GAN.B_CONDITION and c_code is not None:\n","            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n","            c_code = c_code.repeat(1, 1, 4, 4)\n","            # state size (ngf+egf) x 4 x 4\n","            h_c_code = torch.cat((c_code, x_code), 1)\n","            # state size ngf x in_size x in_size\n","            h_c_code = self.jointConv(h_c_code)\n","        else:\n","            h_c_code = x_code\n","\n","        output = self.logits(h_c_code)\n","        if cfg.GAN.B_CONDITION:\n","            out_uncond = self.uncond_logits(x_code)\n","            return [output.view(-1), out_uncond.view(-1)]\n","        else:\n","            return [output.view(-1)]\n","\n","\n","# For 256 x 256 images\n","class D_NET256(nn.Module):\n","    def __init__(self):\n","        super(D_NET256, self).__init__()\n","        self.df_dim = cfg.GAN.DF_DIM\n","        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        ndf = self.df_dim\n","        efg = self.ef_dim\n","        self.img_code_s16 = encode_image_by_16times(ndf)\n","        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n","        self.img_code_s64 = downBlock(ndf * 16, ndf * 32)\n","        self.img_code_s64_1 = Block3x3_leakRelu(ndf * 32, ndf * 16)\n","        self.img_code_s64_2 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n","\n","        self.logits = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","            nn.Sigmoid())\n","\n","        if cfg.GAN.B_CONDITION:\n","            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n","            self.uncond_logits = nn.Sequential(\n","                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","                nn.Sigmoid())\n","\n","    def forward(self, x_var, c_code=None):\n","        x_code = self.img_code_s16(x_var)\n","        x_code = self.img_code_s32(x_code)\n","        x_code = self.img_code_s64(x_code)\n","        x_code = self.img_code_s64_1(x_code)\n","        x_code = self.img_code_s64_2(x_code)\n","\n","        if cfg.GAN.B_CONDITION and c_code is not None:\n","            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n","            c_code = c_code.repeat(1, 1, 4, 4)\n","            # state size (ngf+egf) x 4 x 4\n","            h_c_code = torch.cat((c_code, x_code), 1)\n","            # state size ngf x in_size x in_size\n","            h_c_code = self.jointConv(h_c_code)\n","        else:\n","            h_c_code = x_code\n","\n","        output = self.logits(h_c_code)\n","        if cfg.GAN.B_CONDITION:\n","            out_uncond = self.uncond_logits(x_code)\n","            return [output.view(-1), out_uncond.view(-1)]\n","        else:\n","            return [output.view(-1)]\n","\n","\n","# For 512 x 512 images: Recommended structure, not test yet\n","class D_NET512(nn.Module):\n","    def __init__(self):\n","        super(D_NET512, self).__init__()\n","        self.df_dim = cfg.GAN.DF_DIM\n","        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        ndf = self.df_dim\n","        efg = self.ef_dim\n","        self.img_code_s16 = encode_image_by_16times(ndf)\n","        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n","        self.img_code_s64 = downBlock(ndf * 16, ndf * 32)\n","        self.img_code_s128 = downBlock(ndf * 32, ndf * 64)\n","        self.img_code_s128_1 = Block3x3_leakRelu(ndf * 64, ndf * 32)\n","        self.img_code_s128_2 = Block3x3_leakRelu(ndf * 32, ndf * 16)\n","        self.img_code_s128_3 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n","\n","        self.logits = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","            nn.Sigmoid())\n","\n","        if cfg.GAN.B_CONDITION:\n","            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n","            self.uncond_logits = nn.Sequential(\n","                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","                nn.Sigmoid())\n","\n","    def forward(self, x_var, c_code=None):\n","        x_code = self.img_code_s16(x_var)\n","        x_code = self.img_code_s32(x_code)\n","        x_code = self.img_code_s64(x_code)\n","        x_code = self.img_code_s128(x_code)\n","        x_code = self.img_code_s128_1(x_code)\n","        x_code = self.img_code_s128_2(x_code)\n","        x_code = self.img_code_s128_3(x_code)\n","\n","        if cfg.GAN.B_CONDITION and c_code is not None:\n","            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n","            c_code = c_code.repeat(1, 1, 4, 4)\n","            # state size (ngf+egf) x 4 x 4\n","            h_c_code = torch.cat((c_code, x_code), 1)\n","            # state size ngf x in_size x in_size\n","            h_c_code = self.jointConv(h_c_code)\n","        else:\n","            h_c_code = x_code\n","\n","        output = self.logits(h_c_code)\n","        if cfg.GAN.B_CONDITION:\n","            out_uncond = self.uncond_logits(x_code)\n","            return [output.view(-1), out_uncond.view(-1)]\n","        else:\n","            return [output.view(-1)]\n","\n","\n","# For 1024 x 1024 images: Recommended structure, not test yet\n","class D_NET1024(nn.Module):\n","    def __init__(self):\n","        super(D_NET1024, self).__init__()\n","        self.df_dim = cfg.GAN.DF_DIM\n","        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n","        self.define_module()\n","\n","    def define_module(self):\n","        ndf = self.df_dim\n","        efg = self.ef_dim\n","        self.img_code_s16 = encode_image_by_16times(ndf)\n","        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n","        self.img_code_s64 = downBlock(ndf * 16, ndf * 32)\n","        self.img_code_s128 = downBlock(ndf * 32, ndf * 64)\n","        self.img_code_s256 = downBlock(ndf * 64, ndf * 128)\n","        self.img_code_s256_1 = Block3x3_leakRelu(ndf * 128, ndf * 64)\n","        self.img_code_s256_2 = Block3x3_leakRelu(ndf * 64, ndf * 32)\n","        self.img_code_s256_3 = Block3x3_leakRelu(ndf * 32, ndf * 16)\n","        self.img_code_s256_4 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n","\n","        self.logits = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","            nn.Sigmoid())\n","\n","        if cfg.GAN.B_CONDITION:\n","            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n","            self.uncond_logits = nn.Sequential(\n","                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n","                nn.Sigmoid())\n","\n","    def forward(self, x_var, c_code=None):\n","        x_code = self.img_code_s16(x_var)\n","        x_code = self.img_code_s32(x_code)\n","        x_code = self.img_code_s64(x_code)\n","        x_code = self.img_code_s128(x_code)\n","        x_code = self.img_code_s256(x_code)\n","        x_code = self.img_code_s256_1(x_code)\n","        x_code = self.img_code_s256_2(x_code)\n","        x_code = self.img_code_s256_3(x_code)\n","        x_code = self.img_code_s256_4(x_code)\n","\n","        if cfg.GAN.B_CONDITION and c_code is not None:\n","            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n","            c_code = c_code.repeat(1, 1, 4, 4)\n","            # state size (ngf+egf) x 4 x 4\n","            h_c_code = torch.cat((c_code, x_code), 1)\n","            # state size ngf x in_size x in_size\n","            h_c_code = self.jointConv(h_c_code)\n","        else:\n","            h_c_code = x_code\n","\n","        output = self.logits(h_c_code)\n","        if cfg.GAN.B_CONDITION:\n","            out_uncond = self.uncond_logits(x_code)\n","            return [output.view(-1), out_uncond.view(-1)]\n","        else:\n","            return [output.view(-1)]\n"],"execution_count":0,"outputs":[]}]}